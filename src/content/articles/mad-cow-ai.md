---
title: "Mad Cow AI"
publishedOn: 2025-03-19
author: "<p id=\"\">– Harry Flood</p>"
featuredImage: "/images/articles/mad-cow-ai-1.jpg"
---

Generative AI just keeps getting better and better, until it's indistinguishable from the thing it's mimicking - namely, us. And then it gets smarter than us, until we roll over and submit.

At least that's the drumbeat we hear.

But what if it's bullshit? What if it's as big a bag of bullshit as generative AI itself is threatening to become?

What if the feedback loops we assume will make generative AI better start spinning in the other direction, making it worse? Magnifying its imperfections. Each successive copy is a little more corrupted. Little white lies morph into monstrous, whole-cloth hallucinations … until whatever's left of anything that's authentic on the whole goddamn internet is buried irretrievably in inane slop.

That's the picture a new study out of Rice University is painting.

Researchers in the Digital Signal Processing group at the Houston-based uni threw survey lines across vast swaths of the Internet. They found a Mad Max landscape of billions of roaming bots generating synthetic content 24/7 - which other bots then feed on to learn. As the fake crap becomes an ever-larger proportion of the pool of all material online, the diet of the large language models that power generative AI become increasingly … inorganic. Each output is a little less authentic. Each artifact coming out of the butthole is a little more warped. Corruption breeding corruption … until?

Richard Baraniuk, Rice's C. Sidney Burrus Professor of Electrical and Computer Engineering, called the phenomenon the researchers found an "autophagia" or 'self-consuming' loop." You've heard that language before, in the '80s. That's Mad Cow Disease, the bovine scourge that spread when meat processors cut corners by feeding cows the leftovers of their slaughtered brethren, some of whose brains were infected. Those cows became sick in the head themselves before being ground back into the feedstock. The whole thing snowballed until by the time it was caught the whole industry had been brought to its knees.

If you're a content generator you don't want to know about a study like that. You put your fingers in your ears and go la-la-la. Cuz it's so much cheaper and easier and uncomplicated to put a bot to work for you than to pay a human to make something real.

But we the users can already see it happening.

I keep getting sucked in to a story, suggested "for me" in my feed, of a bear breaking into a hospital. It looks like a news story. The prose is dreadful – clearly Chat GTP wolfshit scraped from low-rent thrillers. And the rising tension is interminably entrained … the better to keep you on the site, before you discover you've been had. When my daughter watches these things she gets physically ill – not because of the philosophical implications of a world going down that path, just from the awful stifling air in an uncanny valley getting ever more toxically uncanny.

Of course, things may not go that route. Ten percent. That, research suggests, is the magic percentage of non-human content there needs to be to prevent the total China Syndrome collapse of all online content into garbage. Stay above that line, and the human overlords can keep the bots in the cotton fields of the not-quite-dead internet, churning out dross, sustainably, forever.
